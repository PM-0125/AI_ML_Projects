{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries Required \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, Concatenate, dot\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('training_set_rel3.tsv', sep='\\t',encoding='latin')\n",
    "essays = df['essay']\n",
    "grades = df['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to load and preprocess the essays and their corresponding grades\n",
    "\n",
    "# Tokenize essays\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(essays)\n",
    "sequences = tokenizer.texts_to_sequences(essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "grades = grades[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "num_test_samples = int(0.2 * data.shape[0])\n",
    "\n",
    "X_train = data[:-num_validation_samples-num_test_samples]\n",
    "y_train = grades[:-num_validation_samples-num_test_samples]\n",
    "X_val = data[-num_validation_samples-num_test_samples:-num_test_samples]\n",
    "y_val = grades[-num_validation_samples-num_test_samples:-num_test_samples]\n",
    "X_test = data[-num_test_samples:]\n",
    "y_test = grades[-num_test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "embedding_layer = Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(128, return_sequences=True))\n",
    "lstm_output = lstm_layer(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mechanism\n",
    "attn_layer = Dense(1, activation='tanh')(lstm_output)\n",
    "attn_layer = tf.squeeze(attn_layer, axis=-1)\n",
    "attn_layer = tf.expand_dims(tf.nn.softmax(attn_layer), axis=-1)\n",
    "context_vector = attn_layer * lstm_output\n",
    "context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(context_vector)\n",
    "model = Model(sequence_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=64)\n",
    "print(\"Test loss: {:.4f}\".format(loss))\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
